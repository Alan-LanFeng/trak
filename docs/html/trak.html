<!doctype html>
<html class="no-js">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />
<link rel="index" title="Index" href="genindex.html" /><link rel="search" title="Search" href="search.html" />

    <!-- Generated with Sphinx 4.4.0 and Furo 2022.12.07 -->
        <title>trak package - TRAK 0.1.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo.css?digest=91d0f0d1c444bdcb17a68e833c7a53903343c195" />
    <link rel="stylesheet" type="text/css" href="_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #f8f8f8;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>



<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="index.html"><div class="brand">TRAK 0.1.0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand" href="index.html">
  
  
  <span class="sidebar-brand-text">TRAK 0.1.0 documentation</span>
  
</a><form class="sidebar-search-container" method="get" action="search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  
</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <section id="trak-package">
<h1>trak package<a class="headerlink" href="#trak-package" title="Permalink to this headline">#</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">#</a></h2>
</section>
<section id="module-trak.gradient_computers">
<span id="trak-gradient-computers-module"></span><h2>trak.gradient_computers module<a class="headerlink" href="#module-trak.gradient_computers" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="trak.gradient_computers.AbstractGradientComputer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.gradient_computers.</span></span><span class="sig-name descname"><span class="pre">AbstractGradientComputer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modelout_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#trak.modelout_functions.AbstractModelOutput" title="trak.modelout_functions.AbstractModelOutput"><span class="pre">trak.modelout_functions.AbstractModelOutput</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/gradient_computers.html#AbstractGradientComputer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.AbstractGradientComputer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Implementations of the GradientComputer class should allow for per-sample
gradients.
This is behavior is enabled with three methods:
- the <cite>load_model_params</cite> method, well, loads model parameters. It can be as</p>
<blockquote>
<div><p>simple as a self.model.load_state_dict(..)</p>
</div></blockquote>
<ul class="simple">
<li><p>the <cite>compute_per_sample_grad</cite> method computes per-sample gradients of the
chosen model output function with respect to the model’s parameters.</p></li>
<li><dl class="simple">
<dt>the <cite>compute_loss_grad</cite> method computes the gradients of the loss function</dt><dd><p>with respect to the model output (which should be a scalar) for every
sample.</p>
</dd>
</dl>
</li>
</ul>
<p>The class attribute <cite>is_functional</cite> is used to determine what implementation
of ModelOutput to use, i.e. whether it should use <cite>functorch</cite>’s functional
models.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.AbstractGradientComputer.compute_loss_grad">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#AbstractGradientComputer.compute_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.AbstractGradientComputer.compute_loss_grad" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.AbstractGradientComputer.compute_per_sample_grad">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">compute_per_sample_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#AbstractGradientComputer.compute_per_sample_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.AbstractGradientComputer.compute_per_sample_grad" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.gradient_computers.AbstractGradientComputer.is_functional">
<span class="sig-name descname"><span class="pre">is_functional</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">True</span></em><a class="headerlink" href="#trak.gradient_computers.AbstractGradientComputer.is_functional" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.AbstractGradientComputer.load_model_params">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_model_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#AbstractGradientComputer.load_model_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.AbstractGradientComputer.load_model_params" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.gradient_computers.FunctionalGradientComputer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.gradient_computers.</span></span><span class="sig-name descname"><span class="pre">FunctionalGradientComputer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modelout_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#trak.modelout_functions.AbstractModelOutput" title="trak.modelout_functions.AbstractModelOutput"><span class="pre">trak.modelout_functions.AbstractModelOutput</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/gradient_computers.html#FunctionalGradientComputer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.FunctionalGradientComputer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.gradient_computers.AbstractGradientComputer" title="trak.gradient_computers.AbstractGradientComputer"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.gradient_computers.AbstractGradientComputer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.FunctionalGradientComputer.compute_loss_grad">
<span class="sig-name descname"><span class="pre">compute_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#FunctionalGradientComputer.compute_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.FunctionalGradientComputer.compute_loss_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the gradient of the loss with respect to the model output
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>\<span class="n">partial</span> \<span class="n">ell</span> <span class="o">/</span> \<span class="n">partial</span> \<span class="n">text</span><span class="p">{</span><span class="n">model</span> <span class="n">output</span><span class="p">}</span>
</pre></div>
</div>
<p>Note: For all applications we considered, we analytically derived the
out-to-loss gradient, thus avoiding the need to do any backward passes
(let alone per-sample grads). If for your application this is not feasible,
you’ll need to subclass this and modify this method to have a structure
similar to the one of <cite>self.get_output</cite>, i.e. something like:
<code class="docutils literal notranslate"><span class="pre">`</span>
<span class="pre">grad_out_to_loss</span> <span class="pre">=</span> <span class="pre">grad(self.model_out_to_loss_grad,</span> <span class="pre">...)</span>
<span class="pre">grads</span> <span class="pre">=</span> <span class="pre">vmap(grad_out_to_loss,</span> <span class="pre">...)</span>
<span class="pre">...</span>
<span class="pre">`</span></code></p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.FunctionalGradientComputer.compute_per_sample_grad">
<span class="sig-name descname"><span class="pre">compute_per_sample_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#FunctionalGradientComputer.compute_per_sample_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.FunctionalGradientComputer.compute_per_sample_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Uses functorch’s vmap (see
<a class="reference external" href="https://pytorch.org/functorch/stable/generated/functorch.vmap.html#functorch.vmap">https://pytorch.org/functorch/stable/generated/functorch.vmap.html#functorch.vmap</a>
for more details) to vectorize the computations of per-sample gradients.</p>
<p>Doesn’t use <cite>batch_size</cite>; only added to follow the abstract method signature.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>batch (Iterable[Tensor]): batch of data
batch_size (int, optional): Defaults to None.</p>
</dd>
<dt>Returns:</dt><dd><dl class="simple">
<dt>Tensor: gradients of the model output function of each sample in the batch</dt><dd><p>with respect to the model’s parameters.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.FunctionalGradientComputer.load_model_params">
<span class="sig-name descname"><span class="pre">load_model_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#FunctionalGradientComputer.load_model_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.FunctionalGradientComputer.load_model_params" title="Permalink to this definition">#</a></dt>
<dd><p>Given a a torch.nn.Module model, inits/updates the func_model, along
with its weights and buffers. See
<a class="reference external" href="https://pytorch.org/functorch/stable/generated/functorch.make_functional_with_buffers.html#functorch-make-functional-with-buffers">https://pytorch.org/functorch/stable/generated/functorch.make_functional_with_buffers.html#functorch-make-functional-with-buffers</a>
for more details on <cite>functorch</cite>’s functional models.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (torch.nn.Module): model to load</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.gradient_computers.IterativeGradientComputer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.gradient_computers.</span></span><span class="sig-name descname"><span class="pre">IterativeGradientComputer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">modelout_fn</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#trak.modelout_functions.AbstractModelOutput" title="trak.modelout_functions.AbstractModelOutput"><span class="pre">trak.modelout_functions.AbstractModelOutput</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/gradient_computers.html#IterativeGradientComputer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.IterativeGradientComputer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.gradient_computers.AbstractGradientComputer" title="trak.gradient_computers.AbstractGradientComputer"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.gradient_computers.AbstractGradientComputer</span></code></a></p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.IterativeGradientComputer.compute_loss_grad">
<span class="sig-name descname"><span class="pre">compute_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#IterativeGradientComputer.compute_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.IterativeGradientComputer.compute_loss_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the gradient of the loss with respect to the model output
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>\<span class="n">partial</span> \<span class="n">ell</span> <span class="o">/</span> \<span class="n">partial</span> \<span class="n">text</span><span class="p">{</span><span class="n">model</span> <span class="n">output</span><span class="p">}</span>
</pre></div>
</div>
<p>Note: For all applications we considered, we analytically derived the
out-to-loss gradient, thus avoiding the need to do any backward passes
(let alone per-sample grads). If for your application this is not feasible,
you’ll need to subclass this and modify this method to have a structure
similar to the one of <cite>self.get_output</cite>, i.e. something like:
<a href="#id1"><span class="problematic" id="id2">``</span></a>`
out_to_loss = self.model_out_to_loss(…)
for ind in range(batch_size):</p>
<blockquote>
<div><p>grads[ind] = torch.autograd.grad(out_to_loss[ind], …)</p>
</div></blockquote>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.IterativeGradientComputer.compute_per_sample_grad">
<span class="sig-name descname"><span class="pre">compute_per_sample_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#IterativeGradientComputer.compute_per_sample_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.IterativeGradientComputer.compute_per_sample_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Computes per-sample gradients of the model output function This
method does not leverage vectorization (and is hence much slower than
its equivalent in <cite>FunctionalGradientComputer</cite>). We recommend that
you use this only if <cite>functorch</cite> is not available to you, e.g. you have
a (very) old version of pytorch.</p>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.gradient_computers.IterativeGradientComputer.is_functional">
<span class="sig-name descname"><span class="pre">is_functional</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">False</span></em><a class="headerlink" href="#trak.gradient_computers.IterativeGradientComputer.is_functional" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.gradient_computers.IterativeGradientComputer.load_model_params">
<span class="sig-name descname"><span class="pre">load_model_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/gradient_computers.html#IterativeGradientComputer.load_model_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.gradient_computers.IterativeGradientComputer.load_model_params" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-trak.modelout_functions">
<span id="trak-modelout-functions-module"></span><h2>trak.modelout_functions module<a class="headerlink" href="#module-trak.modelout_functions" title="Permalink to this headline">#</a></h2>
<p>Here we provide an abstract “model output” class AbstractModelOutput, together with a number
of subclasses for particular applications (vision, language, etc):
- <code class="code docutils literal notranslate"><span class="pre">ImageClassificationModelOutput</span></code>
- <code class="code docutils literal notranslate"><span class="pre">IterImageClassificationModelOutput</span></code>
- <code class="code docutils literal notranslate"><span class="pre">CLIPModelOutput</span></code></p>
<p>These classes implement methods that transform input batches to the desired model output
(e.g. logits, loss, etc).
See Sections 2 &amp; 3 of (TODO: link)[our paper] for more details on what model output functions are
in the context of TRAK and how to use &amp; design them.</p>
<p>See [TODO: docs link] for examples on how to subclass AbstractModelOutput for a task of your choice.</p>
<dl class="py class">
<dt class="sig sig-object py" id="trak.modelout_functions.AbstractModelOutput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.modelout_functions.</span></span><span class="sig-name descname"><span class="pre">AbstractModelOutput</span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#AbstractModelOutput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.AbstractModelOutput" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>See [TODO: docs link] for examples on how to subclass
<code class="code docutils literal notranslate"><span class="pre">AbstractModelOutput</span></code> for a task of your choice.</p>
<p>Subclasses must implement:
- a <code class="code docutils literal notranslate"><span class="pre">get_output</span></code> method that takes in a batch of inputs and model
weights to produce outputs that TRAK will be trained to predict. In the
notation of the paper, <code class="code docutils literal notranslate"><span class="pre">get_output</span></code> should return <span class="math notranslate nohighlight">\(f(z,\theta)\)</span></p>
<ul class="simple">
<li><p>a <code class="code docutils literal notranslate"><span class="pre">get_out_to_loss_grad</span></code> method that takes in a batch of inputs and</p></li>
</ul>
<p>model weights to produce the gradient of the function that transforms the
model outputs above into the loss with respect to the batch. In the notation
of the paper, <code class="code docutils literal notranslate"><span class="pre">get_out_to_loss_grad</span></code> returns (entries along the
diagonal of) <span class="math notranslate nohighlight">\(Q\)</span>.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.AbstractModelOutput.get_out_to_loss_grad">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_out_to_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#AbstractModelOutput.get_out_to_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.AbstractModelOutput.get_out_to_loss_grad" title="Permalink to this definition">#</a></dt>
<dd><p>See Sections 2 &amp; 3 of (TODO: link)[our paper] for more details on
what the out-to-loss functions (in the notation of the paper, <span class="math notranslate nohighlight">\(Q\)</span>)
are in the context of TRAK and how to use &amp; design them.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (torch.nn.Module): model
batch (Iterable[Tensor]): input batch</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: gradient of the out-to-loss function</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.AbstractModelOutput.get_output">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#AbstractModelOutput.get_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.AbstractModelOutput.get_output" title="Permalink to this definition">#</a></dt>
<dd><p>See Sections 2 &amp; 3 of (TODO: link)[our paper] for more details on
what model output functions are in the context of TRAK and how to use &amp;
design them.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (torch.nn.Module): model
batch (Iterable[Tensor]): input batch</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: model output function</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.modelout_functions.</span></span><span class="sig-name descname"><span class="pre">CLIPModelOutput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">float</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">simulated_batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">300</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/modelout_functions.html#CLIPModelOutput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.modelout_functions.AbstractModelOutput" title="trak.modelout_functions.AbstractModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.modelout_functions.AbstractModelOutput</span></code></a></p>
<p>Margin for multimodal contrastive learning (CLIP). See Section 5.1 of
(TODO: link)[our paper] for more details.</p>
<dl class="simple">
<dt>Raises:</dt><dd><p>AssertionError: this model output function requires using additional
CLIP embeddings, which are computed using the <a class="reference internal" href="#trak.modelout_functions.CLIPModelOutput.get_embeddings" title="trak.modelout_functions.CLIPModelOutput.get_embeddings"><code class="xref py py-func docutils literal notranslate"><span class="pre">get_embeddings()</span></code></a>
method. This method should be invoked before featurizing.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.get_embeddings">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_embeddings</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">50000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">embedding_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1024</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocess_fn_img</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">preprocess_fn_txt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#CLIPModelOutput.get_embeddings"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.get_embeddings" title="Permalink to this definition">#</a></dt>
<dd><p>Computes (image and text) embeddings and saves them in the class
attributes <code class="code docutils literal notranslate"><span class="pre">image_embeddings</span></code> and <code class="code docutils literal notranslate"><span class="pre">text_embeddings</span></code>.</p>
<dl>
<dt>Args:</dt><dd><p>model (torch.nn.Module): model
loader (): data loader
batch_size (int): input batch size
size (int, optional): Maximum number of embeddings to compute. Defaults to 50_000.
embedding_dim (int, optional): Dimension of CLIP embedding. Defaults to 1024.
preprocess_fn_img (func, optional): Transforms to apply to images</p>
<blockquote>
<div><p>from the loader before forward pass. Defaults to None.</p>
</div></blockquote>
<dl class="simple">
<dt>preprocess_fn_txt (func, optional): Transforms to apply to images</dt><dd><p>from the loader before forward pass. Defaults to None.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.get_out_to_loss_grad">
<span class="sig-name descname"><span class="pre">get_out_to_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#CLIPModelOutput.get_out_to_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.get_out_to_loss_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the (reweighting term Q in the paper)</p>
<dl class="simple">
<dt>Args:</dt><dd><p>func_model (func): functorch functional model
weights (Iterable[Tensor]): functorch model weights
buffers (Iterable[Tensor]): functorch model buffers
batch (Iterable[Tensor]): input batch</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: out-to-loss (reweighting term) for the input batch</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.get_output">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#CLIPModelOutput.get_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.get_output" title="Permalink to this definition">#</a></dt>
<dd><p>For a given input <span class="math notranslate nohighlight">\(z=(x, y)\)</span> and model parameters <span class="math notranslate nohighlight">\(\theta\)</span>,
let <span class="math notranslate nohighlight">\(\phi(x, \theta)\)</span> be the CLIP image embedding and
<span class="math notranslate nohighlight">\(\psi(y, \theta)\)</span> be the CLIP text embedding. Last, let
<span class="math notranslate nohighlight">\(B\)</span> be a (simulated) batch. This method implements the model
output function
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">-</span>\<span class="n">log</span><span class="p">(</span>\<span class="n">frac</span><span class="p">{</span>\<span class="n">phi</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>\<span class="n">cdot</span> \<span class="n">psi</span><span class="p">(</span><span class="n">y</span><span class="p">)}{</span>\<span class="n">sum_</span><span class="p">{(</span><span class="n">x</span><span class="s1">&#39;, y&#39;</span><span class="p">)</span>\<span class="ow">in</span> <span class="n">B</span><span class="p">}</span>
\<span class="n">phi</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>\<span class="n">cdot</span> \<span class="n">psi</span><span class="p">(</span><span class="n">y</span><span class="s1">&#39;)})</span>
<span class="o">-</span>\<span class="n">log</span><span class="p">(</span>\<span class="n">frac</span><span class="p">{</span>\<span class="n">phi</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>\<span class="n">cdot</span> \<span class="n">psi</span><span class="p">(</span><span class="n">y</span><span class="p">)}{</span>\<span class="n">sum_</span><span class="p">{(</span><span class="n">x</span><span class="s1">&#39;, y&#39;</span><span class="p">)</span>\<span class="ow">in</span> <span class="n">B</span><span class="p">}</span>
\<span class="n">phi</span><span class="p">(</span><span class="n">x</span><span class="s1">&#39;)\cdot \psi(y)})</span>
</pre></div>
</div>
<p>It uses functorch’s functional models to make the per-sample gradient
computations faster.  For more details on what func_model, weights &amp;
buffers are, and how to use them, please refer to
<a class="reference external" href="https://pytorch.org/functorch/stable/">https://pytorch.org/functorch/stable/</a> and
<a class="reference external" href="https://pytorch.org/functorch/stable/notebooks/per_sample_grads.html">https://pytorch.org/functorch/stable/notebooks/per_sample_grads.html</a>.</p>
<p>Note: this method slightly breaks abstraction since it has a different
signature from the abstract <code class="code docutils literal notranslate"><span class="pre">get_output</span></code>. It’s only used
internally by <code class="xref py py-func docutils literal notranslate"><span class="pre">GradientComputer()</span></code> so it shouldn’t be a big problem.
If you’re reading this and feel strongly about it, feel free to make a
PR with a fix.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>func_model (func): functorch functional model
weights (Iterable[Tensor]): functorch model weights
buffers (Iterable[Tensor]): functorch model buffers
image (Tensor): input image, should not have batch dimension
label (Tensor): input label, should not have batch dimension</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: model output for the given image-label pair <span class="math notranslate nohighlight">\(z\)</span> and
weights &amp; buffers <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.image_embeddings">
<span class="sig-name descname"><span class="pre">image_embeddings</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.image_embeddings" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.num_computed_embeddings">
<span class="sig-name descname"><span class="pre">num_computed_embeddings</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.num_computed_embeddings" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.sim_batch_size">
<span class="sig-name descname"><span class="pre">sim_batch_size</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">0</span></em><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.sim_batch_size" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.modelout_functions.CLIPModelOutput.text_embeddings">
<span class="sig-name descname"><span class="pre">text_embeddings</span></span><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">None</span></em><a class="headerlink" href="#trak.modelout_functions.CLIPModelOutput.text_embeddings" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.modelout_functions.ImageClassificationModelOutput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.modelout_functions.</span></span><span class="sig-name descname"><span class="pre">ImageClassificationModelOutput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">float</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/modelout_functions.html#ImageClassificationModelOutput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.ImageClassificationModelOutput" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.modelout_functions.AbstractModelOutput" title="trak.modelout_functions.AbstractModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.modelout_functions.AbstractModelOutput</span></code></a></p>
<p>Margin for (multiclass) image classification. See Section 3.3 of (TODO: link)[our paper]
for more details.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.ImageClassificationModelOutput.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#ImageClassificationModelOutput.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.ImageClassificationModelOutput.forward" title="Permalink to this definition">#</a></dt>
<dd><p>Utility method to make forward passes compatible across different models,
e.g. image classification models take in only the images in the batch,
but CLIP takes in both the images and captions — using this method,
the TRAKer class does not need to be modified when we have a new model
that uses different parts of the input batch.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (Module): model
batch (Iterable[Tensor]): input batch</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: model output (not to be confused with the model output function)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.ImageClassificationModelOutput.get_out_to_loss_grad">
<span class="sig-name descname"><span class="pre">get_out_to_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffers</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#ImageClassificationModelOutput.get_out_to_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.ImageClassificationModelOutput.get_out_to_loss_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the (reweighting term Q in the paper)</p>
<dl class="simple">
<dt>Args:</dt><dd><p>func_model (func): functorch functional model
weights (Iterable[Tensor]): functorch model weights
buffers (Iterable[Tensor]): functorch model buffers
batch (Iterable[Tensor]): input batch</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: out-to-loss (reweighting term) for the input batch</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.ImageClassificationModelOutput.get_output">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">func_model</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weights</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">buffers</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">image</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">label</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#ImageClassificationModelOutput.get_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.ImageClassificationModelOutput.get_output" title="Permalink to this definition">#</a></dt>
<dd><p>For a given input <span class="math notranslate nohighlight">\(z=(x, y)\)</span> and model parameters <span class="math notranslate nohighlight">\(\theta\)</span>,
let <span class="math notranslate nohighlight">\(p(z, \theta)\)</span> be the softmax probability of the correct class.
This method implements the model output function
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>\<span class="n">log</span><span class="p">(</span>\<span class="n">frac</span><span class="p">{</span><span class="n">p</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> \<span class="n">theta</span><span class="p">)}{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> \<span class="n">theta</span><span class="p">)})</span><span class="o">.</span>
</pre></div>
</div>
<p>It uses functorch’s functional models to make the per-sample gradient computations faster.
For more details on what func_model, weights &amp; buffers are, and how to use them, please
refer to <a class="reference external" href="https://pytorch.org/functorch/stable/">https://pytorch.org/functorch/stable/</a> and
<a class="reference external" href="https://pytorch.org/functorch/stable/notebooks/per_sample_grads.html">https://pytorch.org/functorch/stable/notebooks/per_sample_grads.html</a>.</p>
<p>Note: this method slightly breaks abstraction since it has a different
signature from the abstract <code class="code docutils literal notranslate"><span class="pre">get_output</span></code>. It’s only used
internally by <code class="xref py py-func docutils literal notranslate"><span class="pre">GradientComputer()</span></code> so it shouldn’t be a big problem.
If you’re reading this and feel strongly about it, feel free to make a
PR with a fix.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>func_model (func): functorch functional model
weights (Iterable[Tensor]): functorch model weights
buffers (Iterable[Tensor]): functorch model buffers
image (Tensor): input image, should not have batch dimension
label (Tensor): input label, should not have batch dimension</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: model output for the given image-label pair <span class="math notranslate nohighlight">\(z\)</span> and
weights &amp; buffers <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.modelout_functions.IterImageClassificationModelOutput">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.modelout_functions.</span></span><span class="sig-name descname"><span class="pre">IterImageClassificationModelOutput</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">temperature</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/modelout_functions.html#IterImageClassificationModelOutput"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.IterImageClassificationModelOutput" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.modelout_functions.AbstractModelOutput" title="trak.modelout_functions.AbstractModelOutput"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.modelout_functions.AbstractModelOutput</span></code></a></p>
<p>Margin for (multiclass) image classification. See Section 3.3 of (TODO: link)[our paper]
for more details.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.IterImageClassificationModelOutput.get_out_to_loss_grad">
<span class="sig-name descname"><span class="pre">get_out_to_loss_grad</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#IterImageClassificationModelOutput.get_out_to_loss_grad"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.IterImageClassificationModelOutput.get_out_to_loss_grad" title="Permalink to this definition">#</a></dt>
<dd><p>Computes the (reweighting term Q in the paper)</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model (torch.nn.Module): model
batch (Iterable[Tensor]): input batch</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: out-to-loss (reweighting term) for the input batch</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.modelout_functions.IterImageClassificationModelOutput.get_output">
<span class="sig-name descname"><span class="pre">get_output</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">images</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">labels</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/modelout_functions.html#IterImageClassificationModelOutput.get_output"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.modelout_functions.IterImageClassificationModelOutput.get_output" title="Permalink to this definition">#</a></dt>
<dd><p>For a given input <span class="math notranslate nohighlight">\(z=(x, y)\)</span> and model parameters <span class="math notranslate nohighlight">\(\theta\)</span>,
let <span class="math notranslate nohighlight">\(p(z, \theta)\)</span> be the softmax probability of the correct class.
This method implements the model output function
.. math:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>\<span class="n">log</span><span class="p">(</span>\<span class="n">frac</span><span class="p">{</span><span class="n">p</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> \<span class="n">theta</span><span class="p">)}{</span><span class="mi">1</span> <span class="o">-</span> <span class="n">p</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> \<span class="n">theta</span><span class="p">)})</span><span class="o">.</span>
</pre></div>
</div>
<dl class="simple">
<dt>Args:</dt><dd><p>model (torch.nn.Module): model
image (Tensor): input images
label (Tensor): input labels</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: model output for the given image-label pair <span class="math notranslate nohighlight">\(z\)</span> and
model parameters :math:`    heta`.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-trak.projectors">
<span id="trak-projectors-module"></span><h2>trak.projectors module<a class="headerlink" href="#module-trak.projectors" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="trak.projectors.AbstractProjector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.projectors.</span></span><span class="sig-name descname"><span class="pre">AbstractProjector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><a class="reference internal" href="#trak.projectors.ProjectionType" title="trak.projectors.ProjectionType"><span class="pre">trak.projectors.ProjectionType</span></a><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">torch.device</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#AbstractProjector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.AbstractProjector" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Implementations of the Projector class must implement the <cite>project</cite> method,
which takes in model gradients and returns</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.AbstractProjector.project">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">project</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/projectors.html#AbstractProjector.project"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.AbstractProjector.project" title="Permalink to this definition">#</a></dt>
<dd><p>Performs the random projection. Model ID is included
so that we generate different projection matrices for every
model ID.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>grads (Tensor): a batch of gradients to be projected
model_id (int): a unique ID for a checkpoint</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: the projected gradients</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.projectors.BasicProjector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.projectors.</span></span><span class="sig-name descname"><span class="pre">BasicProjector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#trak.projectors.ProjectionType" title="trak.projectors.ProjectionType"><span class="pre">trak.projectors.ProjectionType</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">block_size</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">200</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.float32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#BasicProjector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicProjector" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.projectors.AbstractProjector" title="trak.projectors.AbstractProjector"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.projectors.AbstractProjector</span></code></a></p>
<p>A simple block-wise implementation of the projection. The projection matrix
is generated on-device in blocks. The accumulated result across blocks is
returned.</p>
<p>Note: This class will be significantly slower and have a larger memory
footprint than the CudaProjector. It is recommended that you use this method
only if the CudaProjector is not available to you – e.g. if you don’t have
a CUDA-enabled device with compute capability &gt;=7.0 (see
<a class="reference external" href="https://developer.nvidia.com/cuda-gpus">https://developer.nvidia.com/cuda-gpus</a>).</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.BasicProjector.generate_sketch_matrix">
<span class="sig-name descname"><span class="pre">generate_sketch_matrix</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">generator_state</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#BasicProjector.generate_sketch_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicProjector.generate_sketch_matrix" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.BasicProjector.get_generator_states">
<span class="sig-name descname"><span class="pre">get_generator_states</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#BasicProjector.get_generator_states"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicProjector.get_generator_states" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.BasicProjector.project">
<span class="sig-name descname"><span class="pre">project</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/projectors.html#BasicProjector.project"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicProjector.project" title="Permalink to this definition">#</a></dt>
<dd><p>Performs the random projection. Model ID is included
so that we generate different projection matrices for every
model ID.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>grads (Tensor): a batch of gradients to be projected
model_id (int): a unique ID for a checkpoint</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: the projected gradients</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.projectors.BasicSingleBlockProjector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.projectors.</span></span><span class="sig-name descname"><span class="pre">BasicSingleBlockProjector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#trak.projectors.ProjectionType" title="trak.projectors.ProjectionType"><span class="pre">trak.projectors.ProjectionType</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dtype</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">torch.float16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#BasicSingleBlockProjector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicSingleBlockProjector" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.projectors.AbstractProjector" title="trak.projectors.AbstractProjector"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.projectors.AbstractProjector</span></code></a></p>
<p>A bare-bones, inefficient implementation of the projection, which simply
calls torch’s matmul for the projection step.</p>
<p>Note: for most model sizes (e.g. even for ResNet18), and small projection
dimensions (e.g. anything &gt; 100) this method will OOM on an A100.</p>
<p>Unless you have a good reason to use this class (I cannot think of one, I
added this only for testing purposes), use instead the CudaProjector or
BasicProjector.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.BasicSingleBlockProjector.generate_sketch_matrix">
<span class="sig-name descname"><span class="pre">generate_sketch_matrix</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#BasicSingleBlockProjector.generate_sketch_matrix"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicSingleBlockProjector.generate_sketch_matrix" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.BasicSingleBlockProjector.project">
<span class="sig-name descname"><span class="pre">project</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/projectors.html#BasicSingleBlockProjector.project"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.BasicSingleBlockProjector.project" title="Permalink to this definition">#</a></dt>
<dd><p>Performs the random projection. Model ID is included
so that we generate different projection matrices for every
model ID.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>grads (Tensor): a batch of gradients to be projected
model_id (int): a unique ID for a checkpoint</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: the projected gradients</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.projectors.CudaProjector">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.projectors.</span></span><span class="sig-name descname"><span class="pre">CudaProjector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grad_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_type</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><a class="reference internal" href="#trak.projectors.ProjectionType" title="trak.projectors.ProjectionType"><span class="pre">trak.projectors.ProjectionType</span></a></span></em>, <em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#CudaProjector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.CudaProjector" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.projectors.AbstractProjector" title="trak.projectors.AbstractProjector"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.projectors.AbstractProjector</span></code></a></p>
<p>A performant implementation of the projection for CUDA with compute
capability &gt;= 7.0.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.projectors.CudaProjector.project">
<span class="sig-name descname"><span class="pre">project</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/projectors.html#CudaProjector.project"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.CudaProjector.project" title="Permalink to this definition">#</a></dt>
<dd><p>Performs the random projection. Model ID is included
so that we generate different projection matrices for every
model ID.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>grads (Tensor): a batch of gradients to be projected
model_id (int): a unique ID for a checkpoint</p>
</dd>
<dt>Returns:</dt><dd><p>Tensor: the projected gradients</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.projectors.ProjectionType">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.projectors.</span></span><span class="sig-name descname"><span class="pre">ProjectionType</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">value</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/projectors.html#ProjectionType"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.projectors.ProjectionType" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">str</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">enum.Enum</span></code></p>
<p>An enumeration.</p>
<dl class="py attribute">
<dt class="sig sig-object py" id="trak.projectors.ProjectionType.normal">
<span class="sig-name descname"><span class="pre">normal</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'normal'</span></em><a class="headerlink" href="#trak.projectors.ProjectionType.normal" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py attribute">
<dt class="sig sig-object py" id="trak.projectors.ProjectionType.rademacher">
<span class="sig-name descname"><span class="pre">rademacher</span></span><em class="property"><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="pre">str</span></em><em class="property"><span class="w"> </span><span class="p"><span class="pre">=</span></span><span class="w"> </span><span class="pre">'rademacher'</span></em><a class="headerlink" href="#trak.projectors.ProjectionType.rademacher" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-trak.savers">
<span id="trak-savers-module"></span><h2>trak.savers module<a class="headerlink" href="#module-trak.savers" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.savers.</span></span><span class="sig-name descname"><span class="pre">AbstractSaver</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_dir</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Union</span><span class="p"><span class="pre">[</span></span><span class="pre">pathlib.Path</span><span class="p"><span class="pre">,</span></span><span class="w"> </span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>Implementations of Saver class must implement getters and setters for TRAK
features and scores, as well as intermediate values like gradients and
“out-to-loss-gradient”.</p>
<p>The Saver class also handles the recording of metadata associated with each
TRAK run. For example, hyperparameters like “JL dimension” – the dimension
used for the dimensionality reduction step of TRAk (Johnson-Lindenstrauss
projection).</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver.clear_target_grad_count">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">clear_target_grad_count</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver.clear_target_grad_count"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver.clear_target_grad_count" title="Permalink to this definition">#</a></dt>
<dd><p>Reset the count for how many targets we are scoring</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver.del_grads">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">del_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver.del_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver.del_grads" title="Permalink to this definition">#</a></dt>
<dd><p>Delete the intermediate values (gradients) for a given model id</p>
<dl>
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint
target (bool): if True, delete the gradients of the target samples,</p>
<blockquote>
<div><p>otherwise delete the train set gradients.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver.load_store">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_store</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver.load_store"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver.load_store" title="Permalink to this definition">#</a></dt>
<dd><p>Populates the self.current_* attributes with data for the
given model ID (checkpoint).</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver.load_target_store">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">load_target_store</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver.load_target_store"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver.load_target_store" title="Permalink to this definition">#</a></dt>
<dd><p>Loads/initializes metadata and store arrays for target results and
features (gradients)</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint
num_targets (int): number of target samples that will be scored</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver.register_model_id">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">register_model_id</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver.register_model_id"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver.register_model_id" title="Permalink to this definition">#</a></dt>
<dd><p>Create metadata for a new model ID (checkpoint).</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.AbstractSaver.serialize_model_id_metadata">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">serialize_model_id_metadata</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#AbstractSaver.serialize_model_id_metadata"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.AbstractSaver.serialize_model_id_metadata" title="Permalink to this definition">#</a></dt>
<dd><p>Write to disk / commit any updates to the metadata associated
to a given model ID</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.savers.MmapSaver">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.savers.</span></span><span class="sig-name descname"><span class="pre">MmapSaver</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_dir</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">metadata</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">train_set_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.savers.AbstractSaver" title="trak.savers.AbstractSaver"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.savers.AbstractSaver</span></code></a></p>
<p>A saver that uses memory-mapped numpy arrays. This makes small reads and
writes (e.g.) during featurizing feasible without loading the entire file
into memory.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.clear_target_grad_count">
<span class="sig-name descname"><span class="pre">clear_target_grad_count</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.clear_target_grad_count"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.clear_target_grad_count" title="Permalink to this definition">#</a></dt>
<dd><p>Reset the count for how many targets we are scoring</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.del_grads">
<span class="sig-name descname"><span class="pre">del_grads</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.del_grads"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.del_grads" title="Permalink to this definition">#</a></dt>
<dd><p>Delete the intermediate values (gradients) for a given model id</p>
<dl>
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint
target (bool): if True, delete the gradients of the target samples,</p>
<blockquote>
<div><p>otherwise delete the train set gradients.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.init_store">
<span class="sig-name descname"><span class="pre">init_store</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.init_store"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.init_store" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.load_store">
<span class="sig-name descname"><span class="pre">load_store</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'r+'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.load_store"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.load_store" title="Permalink to this definition">#</a></dt>
<dd><p>This method uses numpy memmaps for serializing the TRAK results and
intermediate values.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint
mode (str, optional): Defaults to ‘r+’.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.load_target_store">
<span class="sig-name descname"><span class="pre">load_target_store</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mode</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">'r+'</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.load_target_store"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.load_target_store" title="Permalink to this definition">#</a></dt>
<dd><p>_summary_</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): _description_
num_targets (int): _description_</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.register_model_id">
<span class="sig-name descname"><span class="pre">register_model_id</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_allow_featurizing_already_registered</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.register_model_id"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.register_model_id" title="Permalink to this definition">#</a></dt>
<dd><p>This method
1) checks if the model ID already exists in the save dir
2) if yes, it raises an error since model IDs must be unique
3) if not, it creates a metadata file for it and initalizes store mmaps</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
<dt>Raises:</dt><dd><p>ModelIDException: raised if the model ID to be registered already
exists</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.save_scores">
<span class="sig-name descname"><span class="pre">save_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">scores</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.save_scores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.save_scores" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.savers.MmapSaver.serialize_model_id_metadata">
<span class="sig-name descname"><span class="pre">serialize_model_id_metadata</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_id</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/savers.html#MmapSaver.serialize_model_id_metadata"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.MmapSaver.serialize_model_id_metadata" title="Permalink to this definition">#</a></dt>
<dd><p>Write to disk / commit any updates to the metadata associated
to a given model ID</p>
<dl class="simple">
<dt>Args:</dt><dd><p>model_id (int): a unique ID for a checkpoint</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py exception">
<dt class="sig sig-object py" id="trak.savers.ModelIDException">
<em class="property"><span class="pre">exception</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.savers.</span></span><span class="sig-name descname"><span class="pre">ModelIDException</span></span><a class="reference internal" href="_modules/trak/savers.html#ModelIDException"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.savers.ModelIDException" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Exception</span></code></p>
<p>A minimal custom exception for errors related to model IDs</p>
</dd></dl>

</section>
<section id="module-trak.score_computers">
<span id="trak-score-computers-module"></span><h2>trak.score_computers module<a class="headerlink" href="#module-trak.score_computers" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="trak.score_computers.AbstractScoreComputer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.score_computers.</span></span><span class="sig-name descname"><span class="pre">AbstractScoreComputer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/score_computers.html#AbstractScoreComputer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.AbstractScoreComputer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">abc.ABC</span></code></p>
<p>The <code class="code docutils literal notranslate"><span class="pre">ScoreComputer</span></code> class
Implementations of the ScoreComputer class must implement three methods:
- <code class="code docutils literal notranslate"><span class="pre">get_xtx</span></code>
- <code class="code docutils literal notranslate"><span class="pre">get_x_xtx_inv</span></code>
- <code class="code docutils literal notranslate"><span class="pre">get_scores</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.AbstractScoreComputer.get_scores">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#AbstractScoreComputer.get_scores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.AbstractScoreComputer.get_scores" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.AbstractScoreComputer.get_x_xtx_inv">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_x_xtx_inv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xtx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#AbstractScoreComputer.get_x_xtx_inv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.AbstractScoreComputer.get_x_xtx_inv" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.AbstractScoreComputer.get_xtx">
<em class="property"><span class="pre">abstract</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">get_xtx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#AbstractScoreComputer.get_xtx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.AbstractScoreComputer.get_xtx" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.score_computers.BasicScoreComputer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.score_computers.</span></span><span class="sig-name descname"><span class="pre">BasicScoreComputer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">CUDA_MAX_DIM_SIZE</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">100000</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/score_computers.html#BasicScoreComputer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicScoreComputer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.score_computers.AbstractScoreComputer" title="trak.score_computers.AbstractScoreComputer"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.score_computers.AbstractScoreComputer</span></code></a></p>
<p>An implementation of <code class="code docutils literal notranslate"><span class="pre">ScoreComputer</span></code> that computes matmuls in a
block-wise manner.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.BasicScoreComputer.get_scores">
<span class="sig-name descname"><span class="pre">get_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#BasicScoreComputer.get_scores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicScoreComputer.get_scores" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.BasicScoreComputer.get_x_xtx_inv">
<span class="sig-name descname"><span class="pre">get_x_xtx_inv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xtx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#BasicScoreComputer.get_x_xtx_inv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicScoreComputer.get_x_xtx_inv" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.BasicScoreComputer.get_xtx">
<span class="sig-name descname"><span class="pre">get_xtx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#BasicScoreComputer.get_xtx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicScoreComputer.get_xtx" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="trak.score_computers.BasicSingleBlockScoreComputer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.score_computers.</span></span><span class="sig-name descname"><span class="pre">BasicSingleBlockScoreComputer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">device</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/score_computers.html#BasicSingleBlockScoreComputer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicSingleBlockScoreComputer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <a class="reference internal" href="#trak.score_computers.AbstractScoreComputer" title="trak.score_computers.AbstractScoreComputer"><code class="xref py py-class docutils literal notranslate"><span class="pre">trak.score_computers.AbstractScoreComputer</span></code></a></p>
<p>A bare-bones implementation of <code class="code docutils literal notranslate"><span class="pre">ScoreComputer</span></code> that will likely
OOM for almost all applications. Here for testing purposes only. Unless you
have a good reason not to, you should use <a class="reference internal" href="#trak.score_computers.BasicScoreComputer" title="trak.score_computers.BasicScoreComputer"><code class="xref py py-func docutils literal notranslate"><span class="pre">BasicScoreComputer()</span></code></a>
instead.</p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.BasicSingleBlockScoreComputer.get_scores">
<span class="sig-name descname"><span class="pre">get_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">features</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">target_grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#BasicSingleBlockScoreComputer.get_scores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicSingleBlockScoreComputer.get_scores" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.BasicSingleBlockScoreComputer.get_x_xtx_inv">
<span class="sig-name descname"><span class="pre">get_x_xtx_inv</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">xtx</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#BasicSingleBlockScoreComputer.get_x_xtx_inv"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicSingleBlockScoreComputer.get_x_xtx_inv" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.score_computers.BasicSingleBlockScoreComputer.get_xtx">
<span class="sig-name descname"><span class="pre">get_xtx</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.Tensor</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/score_computers.html#BasicSingleBlockScoreComputer.get_xtx"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.score_computers.BasicSingleBlockScoreComputer.get_xtx" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-trak.traker">
<span id="trak-traker-module"></span><h2>trak.traker module<a class="headerlink" href="#module-trak.traker" title="Permalink to this headline">#</a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="trak.traker.TRAKer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">trak.traker.</span></span><span class="sig-name descname"><span class="pre">TRAKer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="pre">model:</span> <span class="pre">torch.nn.modules.module.Module,</span> <span class="pre">task:</span> <span class="pre">typing.Union[trak.modelout_functions.AbstractModelOutput,</span> <span class="pre">str],</span> <span class="pre">train_set_size:</span> <span class="pre">int,</span> <span class="pre">save_dir:</span> <span class="pre">str</span> <span class="pre">=</span> <span class="pre">'./trak_results',</span> <span class="pre">device:</span> <span class="pre">typing.Union[str,</span> <span class="pre">torch.device]</span> <span class="pre">=</span> <span class="pre">'cuda',</span> <span class="pre">gradient_computer:</span> <span class="pre">trak.gradient_computers.AbstractGradientComputer</span> <span class="pre">=</span> <span class="pre">&lt;class</span> <span class="pre">'trak.gradient_computers.FunctionalGradientComputer'&gt;,</span> <span class="pre">projector:</span> <span class="pre">typing.Optional[trak.projectors.AbstractProjector]</span> <span class="pre">=</span> <span class="pre">None,</span> <span class="pre">proj_dim:</span> <span class="pre">int</span> <span class="pre">=</span> <span class="pre">2048</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/trak/traker.html#TRAKer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer" title="Permalink to this definition">#</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.featurize">
<span class="sig-name descname"><span class="pre">featurize</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.featurize"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.featurize" title="Permalink to this definition">#</a></dt>
<dd><p>Creates TRAK features for the given batch by computing the gradient
of the model output function and projecting it. In the notation of the
paper, for an input pair <span class="math notranslate nohighlight">\(z=(x,y)\)</span>, model parameters
<span class="math notranslate nohighlight">\(\theta\)</span>, and JL projection matrix <span class="math notranslate nohighlight">\(P\)</span>, this method
computes <span class="math notranslate nohighlight">\(P^\top \nabla_\theta f(z_i, \theta)\)</span>.
Additionally, this method computes the gradient of the out-to-loss
function (in the notation of the paper, the <span class="math notranslate nohighlight">\(Q\)</span> term in Section
3.4).</p>
<p>Either <code class="code docutils literal notranslate"><span class="pre">inds</span></code> or <code class="code docutils literal notranslate"><span class="pre">num_samples</span></code> must be specified. Using
<code class="code docutils literal notranslate"><span class="pre">num_samples</span></code> will write sequentially into the internal store of
the <a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>batch (Iterable[Tensor]): input batch
inds (Optional[Iterable[int]], optional): Indices of the batch
samples in the train set. Defaults to None.
num_samples (Optional[int], optional): Number of samples in the
batch. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.finalize_features">
<span class="sig-name descname"><span class="pre">finalize_features</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">del_grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.finalize_features"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.finalize_features" title="Permalink to this definition">#</a></dt>
<dd><p>For a set of checkpoints <span class="math notranslate nohighlight">\(C\)</span> (specified by model IDs), and
gradients <span class="math notranslate nohighlight">\(\{ \Phi_c \}_{c\in C}\)</span>, this method computes
<span class="math notranslate nohighlight">\(\Phi_c (\Phi_c^\top\Phi_c)^{-1}\)</span> for all <span class="math notranslate nohighlight">\(c\in C\)</span>
and stores the results in the internal store of the <a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a>
class.</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>model_ids (Iterable[int], optional): A list of model IDs for which</dt><dd><p>features should be finalized. If None, features are finalized
for all model IDs in the <code class="code docutils literal notranslate"><span class="pre">save_dir</span></code> of the <a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a>
class. Defaults to None.</p>
</dd>
</dl>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.finalize_scores">
<span class="sig-name descname"><span class="pre">finalize_scores</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_ids</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">del_grads</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">bool</span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">exp_name</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">str</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.finalize_scores"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.finalize_scores" title="Permalink to this definition">#</a></dt>
<dd><p>This method computes the final TRAK scores for the given targets,
train samples, and model checkpoints (specified by model IDs).</p>
<dl class="simple">
<dt>Args:</dt><dd><dl class="simple">
<dt>model_ids (Iterable[int], optional): A list of model IDs for which</dt><dd><p>scores should be finalized. If None, scores are computed
for all model IDs in the <code class="code docutils literal notranslate"><span class="pre">save_dir</span></code> of the <a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a>
class. Defaults to None.</p>
</dd>
<dt>del_grads (bool, optional): If True, the target gradients</dt><dd><p>(intermediate results) are deleted from the internal store of the
<a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a> class.  Defaults to True.</p>
</dd>
<dt>exp_name (str, optional): Used to name the scores <code class="code docutils literal notranslate"><span class="pre">.npy</span></code></dt><dd><p>array produced by this method in the <code class="code docutils literal notranslate"><span class="pre">save_dir</span></code> of the
<a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a> class. If None, a random uuid is generated.
Defaults to None.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>Tensor: TRAK scores</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.init_projector">
<span class="sig-name descname"><span class="pre">init_projector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">projector</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">proj_dim</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.init_projector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.init_projector" title="Permalink to this definition">#</a></dt>
<dd><p>Initialize the projector for a traker class</p>
<dl class="simple">
<dt>Args:</dt><dd><p>projector (AbstractProjector): JL projector</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.load_checkpoint">
<span class="sig-name descname"><span class="pre">load_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">_allow_featurizing_already_registered</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.load_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.load_checkpoint" title="Permalink to this definition">#</a></dt>
<dd><p>Loads state dictionary for the given checkpoint; initializes arrays
to store TRAK features for that checkpoint, tied to the model ID.</p>
<dl>
<dt>Args:</dt><dd><p>checkpoint (Iterable[Tensor]): state_dict to load
model_id (int): a unique ID for a checkpoint
_allow_featurizing_already_registered (bool, optional): Only use if</p>
<blockquote>
<div><p>you want to override the default behaviour that
<code class="code docutils literal notranslate"><span class="pre">featurize</span></code> is forbidden on already registered model IDs.
Defaults to None.</p>
</div></blockquote>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.score">
<span class="sig-name descname"><span class="pre">score</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">batch</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">inds</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_samples</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Optional</span><span class="p"><span class="pre">[</span></span><span class="pre">int</span><span class="p"><span class="pre">]</span></span></span><span class="w"> </span><span class="o"><span class="pre">=</span></span><span class="w"> </span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.score"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.score" title="Permalink to this definition">#</a></dt>
<dd><p>This method computes the (intermediate per-checkpoint) TRAK scores
for a batch of targets and stores them in the internal store of the
<a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a> class.</p>
<p>Either <code class="code docutils literal notranslate"><span class="pre">inds</span></code> or <code class="code docutils literal notranslate"><span class="pre">num_samples</span></code> must be specified. Using
<code class="code docutils literal notranslate"><span class="pre">num_samples</span></code> will write sequentially into the internal store of
the <a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a>.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>batch (Iterable[Tensor]): input batch
inds (Optional[Iterable[int]], optional): Indices of the batch
samples in the train set. Defaults to None.
num_samples (Optional[int], optional): Number of samples in the
batch. Defaults to None.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="trak.traker.TRAKer.start_scoring_checkpoint">
<span class="sig-name descname"><span class="pre">start_scoring_checkpoint</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">checkpoint</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">Iterable</span><span class="p"><span class="pre">[</span></span><span class="pre">torch.Tensor</span><span class="p"><span class="pre">]</span></span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_id</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_targets</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">int</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">None</span></span></span><a class="reference internal" href="_modules/trak/traker.html#TRAKer.start_scoring_checkpoint"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.traker.TRAKer.start_scoring_checkpoint" title="Permalink to this definition">#</a></dt>
<dd><p>This method prepares the internal store of the <a class="reference internal" href="#trak.traker.TRAKer" title="trak.traker.TRAKer"><code class="xref py py-func docutils literal notranslate"><span class="pre">TRAKer()</span></code></a> class
to start computing scores for a set of targets.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>checkpoint (Iterable[Tensor]): model checkpoint (state dict)
model_id (int): a unique ID for a checkpoint
num_targets (int): number of targets to score</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="module-trak.utils">
<span id="trak-utils-module"></span><h2>trak.utils module<a class="headerlink" href="#module-trak.utils" title="Permalink to this headline">#</a></h2>
<dl class="py function">
<dt class="sig sig-object py" id="trak.utils.get_num_params">
<span class="sig-prename descclassname"><span class="pre">trak.utils.</span></span><span class="sig-name descname"><span class="pre">get_num_params</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">int</span></span></span><a class="reference internal" href="_modules/trak/utils.html#get_num_params"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.utils.get_num_params" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="trak.utils.get_params_dict">
<span class="sig-prename descclassname"><span class="pre">trak.utils.</span></span><span class="sig-name descname"><span class="pre">get_params_dict</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model</span></span><span class="p"><span class="pre">:</span></span><span class="w"> </span><span class="n"><span class="pre">torch.nn.modules.module.Module</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">list</span></span></span><a class="reference internal" href="_modules/trak/utils.html#get_params_dict"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.utils.get_params_dict" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="trak.utils.is_not_buffer">
<span class="sig-prename descclassname"><span class="pre">trak.utils.</span></span><span class="sig-name descname"><span class="pre">is_not_buffer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ind</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params_dict</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">bool</span></span></span><a class="reference internal" href="_modules/trak/utils.html#is_not_buffer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.utils.is_not_buffer" title="Permalink to this definition">#</a></dt>
<dd></dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="trak.utils.parameters_to_vector">
<span class="sig-prename descclassname"><span class="pre">trak.utils.</span></span><span class="sig-name descname"><span class="pre">parameters_to_vector</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">parameters</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/utils.html#parameters_to_vector"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.utils.parameters_to_vector" title="Permalink to this definition">#</a></dt>
<dd><p>Same as <a class="reference external" href="https://pytorch.org/docs/stable/generated/torch.nn.utils.parameters_to_vector.html">https://pytorch.org/docs/stable/generated/torch.nn.utils.parameters_to_vector.html</a>
but with <cite>reshape</cite> instead of <cite>view</cite> to avoid a pesky error.</p>
</dd></dl>

<dl class="py function">
<dt class="sig sig-object py" id="trak.utils.vectorize_and_ignore_buffers">
<span class="sig-prename descclassname"><span class="pre">trak.utils.</span></span><span class="sig-name descname"><span class="pre">vectorize_and_ignore_buffers</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">g</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">params_dict</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span> <span class="sig-return"><span class="sig-return-icon">&#x2192;</span> <span class="sig-return-typehint"><span class="pre">torch.Tensor</span></span></span><a class="reference internal" href="_modules/trak/utils.html#vectorize_and_ignore_buffers"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#trak.utils.vectorize_and_ignore_buffers" title="Permalink to this definition">#</a></dt>
<dd><p>gradients are given as a tuple (grad_w0, grad_w1, … grad_wp)
where p is the number of weight matrices. each grad_wi has shape
[batch_size, …]
this f-n flattens g to have shape [batch_size, num_params]</p>
</dd></dl>

</section>
<section id="module-trak">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-trak" title="Permalink to this headline">#</a></h2>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          
          
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; 2023, Kristian Georgiev
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">trak package</a><ul>
<li><a class="reference internal" href="#submodules">Submodules</a></li>
<li><a class="reference internal" href="#module-trak.gradient_computers">trak.gradient_computers module</a></li>
<li><a class="reference internal" href="#module-trak.modelout_functions">trak.modelout_functions module</a></li>
<li><a class="reference internal" href="#module-trak.projectors">trak.projectors module</a></li>
<li><a class="reference internal" href="#module-trak.savers">trak.savers module</a></li>
<li><a class="reference internal" href="#module-trak.score_computers">trak.score_computers module</a></li>
<li><a class="reference internal" href="#module-trak.traker">trak.traker module</a></li>
<li><a class="reference internal" href="#module-trak.utils">trak.utils module</a></li>
<li><a class="reference internal" href="#module-trak">Module contents</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/scripts/furo.js"></script>
    <script async="async" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>