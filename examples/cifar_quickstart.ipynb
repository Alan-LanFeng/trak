{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5f060ac-ecb3-4129-9ea9-238b3fd7afaa",
   "metadata": {},
   "source": [
    "# Train and save model checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ec6fa04-de0a-4e73-8b35-a4f08bf871c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import wget\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from torch.nn import CrossEntropyLoss, Conv2d, BatchNorm2d\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a16573fd-bdfc-48ad-a42e-a16f4fb40a51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Resnet9\n",
    "class Mul(torch.nn.Module):\n",
    "    def __init__(self, weight):\n",
    "        super(Mul, self).__init__()\n",
    "        self.weight = weight\n",
    "    def forward(self, x): return x * self.weight\n",
    "\n",
    "\n",
    "class Flatten(torch.nn.Module):\n",
    "    def forward(self, x): return x.view(x.size(0), -1)\n",
    "\n",
    "\n",
    "class Residual(torch.nn.Module):\n",
    "    def __init__(self, module):\n",
    "        super(Residual, self).__init__()\n",
    "        self.module = module\n",
    "    def forward(self, x): return x + self.module(x)\n",
    "\n",
    "\n",
    "def construct_rn9(num_classes=10):\n",
    "    def conv_bn(channels_in, channels_out, kernel_size=3, stride=1, padding=1, groups=1):\n",
    "        return torch.nn.Sequential(\n",
    "                torch.nn.Conv2d(channels_in, channels_out, kernel_size=kernel_size,\n",
    "                            stride=stride, padding=padding, groups=groups, bias=False),\n",
    "                torch.nn.BatchNorm2d(channels_out),\n",
    "                torch.nn.ReLU(inplace=True)\n",
    "        )\n",
    "    model = torch.nn.Sequential(\n",
    "        conv_bn(3, 64, kernel_size=3, stride=1, padding=1),\n",
    "        conv_bn(64, 128, kernel_size=5, stride=2, padding=2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(128, 128), conv_bn(128, 128))),\n",
    "        conv_bn(128, 256, kernel_size=3, stride=1, padding=1),\n",
    "        torch.nn.MaxPool2d(2),\n",
    "        Residual(torch.nn.Sequential(conv_bn(256, 256), conv_bn(256, 256))),\n",
    "        conv_bn(256, 128, kernel_size=3, stride=1, padding=0),\n",
    "        torch.nn.AdaptiveMaxPool2d((1, 1)),\n",
    "        Flatten(),\n",
    "        torch.nn.Linear(128, num_classes, bias=False),\n",
    "        Mul(0.2)\n",
    "    )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23be39c9-b4a5-4c8c-b665-c819151745df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataloader(batch_size=256, num_workers=8, split='train'):\n",
    "    \n",
    "    transforms = torchvision.transforms.Compose(\n",
    "                    [torchvision.transforms.RandomHorizontalFlip(),\n",
    "                     torchvision.transforms.RandomAffine(0),\n",
    "                     torchvision.transforms.ToTensor(),\n",
    "                     torchvision.transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.201))])\n",
    "\n",
    "    is_train = (split == 'train')\n",
    "    dataset = torchvision.datasets.CIFAR10(root='/tmp/cifar/', download=True, train=is_train, transform=transforms)\n",
    "    loader = torch.utils.data.DataLoader(dataset=dataset, shuffle=False, batch_size=batch_size, num_workers=num_workers)\n",
    "    \n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f949d611-c408-4fe0-a00a-e68006e766fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, loader, lr=0.4, epochs=24, momentum=0.9, weight_decay=5e-4, lr_peak_epoch=5, label_smoothing=0.0):\n",
    "    opt = SGD(model.parameters(), lr=lr, momentum=momentum, weight_decay=weight_decay)\n",
    "    iters_per_epoch = len(loader)\n",
    "    # Cyclic LR with single triangle\n",
    "    lr_schedule = np.interp(np.arange((epochs+1) * iters_per_epoch),\n",
    "                            [0, lr_peak_epoch * iters_per_epoch, epochs * iters_per_epoch],\n",
    "                            [0, 1, 0])\n",
    "    scheduler = lr_scheduler.LambdaLR(opt, lr_schedule.__getitem__)\n",
    "    scaler = GradScaler()\n",
    "    loss_fn = CrossEntropyLoss(label_smoothing=label_smoothing)\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        model_count = 0\n",
    "        for it, (ims, labs) in enumerate(loader):\n",
    "            ims = ims.float().cuda()\n",
    "            labs = labs.cuda()\n",
    "            opt.zero_grad(set_to_none=True)\n",
    "            with autocast():\n",
    "                out = model(ims)\n",
    "                loss = loss_fn(out, labs)\n",
    "\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(opt)\n",
    "            scaler.update()\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfb400b1-9646-4352-a803-ae8cb1ee7b1a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models..:   0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models..:  33%|███▎      | 1/3 [01:27<02:55, 87.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models..:  67%|██████▋   | 2/3 [02:53<01:26, 86.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training models..: 100%|██████████| 3/3 [04:19<00:00, 86.65s/it]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('./checkpoints', exist_ok=True)\n",
    "\n",
    "for i in tqdm(range(3), desc='Training models..'):\n",
    "    model = construct_rn9().to(memory_format=torch.channels_last).cuda()\n",
    "    loader_train = get_dataloader(batch_size=512, split='train')\n",
    "    train(model, loader_train)\n",
    "    \n",
    "    torch.save(model.state_dict(), f'./checkpoints/sd_{i}.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73561d60-eb99-462a-9c1b-93fa6db800b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ckpt_files = list(Path('./checkpoints').rglob('*.pt'))\n",
    "ckpts = [torch.load(ckpt, map_location='cpu') for ckpt in ckpt_files]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41ff92a8-1d9e-4e63-8a2b-63f97085d020",
   "metadata": {},
   "source": [
    "# Set up the TRAKer class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19cf723c-d1b2-425b-a1e6-265bdedbae77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = construct_rn9().to(memory_format=torch.channels_last).cuda()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9804779-3229-47a2-84d8-771eb7568e1b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Existing IDs in /tmp/trak_store: []\n"
     ]
    }
   ],
   "source": [
    "from trak import TRAKer\n",
    "\n",
    "traker = TRAKer(model=model,\n",
    "                task='image_classification',\n",
    "                proj_dim=1024,\n",
    "                save_dir='/tmp/trak_store',\n",
    "                train_set_size=len(loader_train.dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "188a1582-b725-4fa7-94da-51b5bd62b216",
   "metadata": {},
   "source": [
    "# Compute TRAK features for train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "89886b24-27f2-4876-9e56-a7ed368fe3c0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "loader_train = get_dataloader(batch_size=batch_size, split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48bbce69-67d0-49d6-8467-6f8602c89154",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [01:11<00:00, 23.81s/it]\n",
      "Finalizing features for all model IDs..: 100%|██████████| 3/3 [00:01<00:00,  2.58it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "for model_id, ckpt in enumerate(tqdm(ckpts)):\n",
    "    traker.load_checkpoint(ckpt, model_id=model_id)\n",
    "    for batch in loader_train:\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        traker.featurize(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "traker.finalize_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18430d04-e09b-4ec3-8104-8b86bc468c9b",
   "metadata": {},
   "source": [
    "# Compute TRAK scores for targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "96d6fbe7-2d76-47b5-8f35-a42d63705480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "loader_targets = get_dataloader(batch_size=batch_size, split='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a6629868-7026-4e9f-bbea-1d69515d6944",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:15<00:00,  5.21s/it]\n",
      "Finalizing scores for all model IDs..: 100%|██████████| 3/3 [00:00<00:00, 10.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving scores in /tmp/trak_store/scores/scores_150a5fe1-7655-46c3-9bd0-ebee4feeea8d.npy\n"
     ]
    }
   ],
   "source": [
    "for model_id, ckpt in enumerate(tqdm(ckpts)):\n",
    "    traker.start_scoring_checkpoint(ckpt,\n",
    "                                    model_id=model_id,\n",
    "                                    num_targets=len(loader_targets.dataset))\n",
    "    for batch in loader_targets:\n",
    "        batch = [x.cuda() for x in batch]\n",
    "        traker.score(batch=batch, num_samples=batch[0].shape[0])\n",
    "\n",
    "scores = traker.finalize_scores()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbe341a-681c-4ea0-9685-18910e32485c",
   "metadata": {},
   "source": [
    "# Bonus: evaluate counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d1e013-942a-426f-a6c0-327857c284bb",
   "metadata": {
    "tags": []
   },
   "source": [
    "We exactly follow the steps in https://docs.ffcv.io/ffcv_examples/cifar10.html. Additionally, we train on *subsets* of CIFAR-10, parametrized by the `masks` arrays below. We collect the model outputs for each retraining on a different subset (mask) in a separate array `margins`.\n",
    "\n",
    "We train a total of 10,000 models. Note that this is not necessary to get TRAK scores. This step is only necessary to get (very high quality) LDS correlation estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39ee710b-30e9-4bb1-9f4d-eb145b10b7d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5ba25042-2b4d-4501-b611-4ac7eb716727",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def eval_correlations(scores, tmp_path):\n",
    "    masks_url = '/url/to/masks'  # dropbox link coming soon\n",
    "    margins_url = '/url/to/margins'\n",
    "\n",
    "    masks_path = Path(tmp_path).joinpath('mask.npy')\n",
    "    wget.download(masks_url, out=str(masks_path), bar=None)\n",
    "    # num masks, num train samples\n",
    "    masks = torch.as_tensor(np.load(masks_path, mmap_mode='r')).float()\n",
    "\n",
    "    margins_path = Path(tmp_path).joinpath('val_margins.npy')\n",
    "    wget.download(margins_url, out=str(margins_path), bar=None)\n",
    "    # num , num val samples\n",
    "    margins = torch.as_tensor(np.load(margins_path, mmap_mode='r'))\n",
    "\n",
    "    val_inds = np.arange(10_000)\n",
    "    preds = masks @ scores\n",
    "    rs = []\n",
    "    ps = []\n",
    "    for ind, j in tqdm(enumerate(val_inds)):\n",
    "        r, p = spearmanr(preds[:, ind], margins[:, j])\n",
    "        rs.append(r)\n",
    "        ps.append(p)\n",
    "    rs, ps = np.array(rs), np.array(ps)\n",
    "    print(f'Correlation: {rs.mean()} (avg p value {ps.mean()})')\n",
    "    return rs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b9e974-c668-4b91-a4e0-d362652af13c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "eval_correlations(scores.cpu(), '.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
